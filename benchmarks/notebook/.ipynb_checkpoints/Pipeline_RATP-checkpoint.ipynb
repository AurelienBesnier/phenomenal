{
 "metadata": {
  "name": "",
  "signature": "sha256:f21d520efb78ed6ee39bfe3dfe03dd5e53d75e63773ec14f6acf8447e732c57c"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      " Pipeline - RATP"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "0. Incorporate display (optional)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run the cell above if you want displaying images in the notebook"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "1. Data set:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Download and extract data set : https://gforge.inria.fr/frs/download.php/file/35148/data_set_0962_A310_ARCH2013-05-13.zip\n",
      "\n",
      "And define data_directory path variable like this :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Example :\n",
      "data_directory = \"..\\\\..\\\\local\\\\data_set_0962_A310_ARCH2013-05-13\\\\\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "2. Original Images :"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2.1 Load"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cv2\n",
      "import alinea.phenomenal.misc\n",
      "\n",
      "files = alinea.phenomenal.misc.load_files(data_directory)\n",
      "\n",
      "# Convert\n",
      "\n",
      "images = dict()\n",
      "for pot_id in files:\n",
      "    images[pot_id] = dict()\n",
      "    for date in files[pot_id]:\n",
      "        images[pot_id][date] = alinea.phenomenal.misc.load_images(files[pot_id][date], cv2.IMREAD_UNCHANGED)\n",
      "        \n",
      "        print pot_id, date"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0962 2013-05-24\n",
        "0962"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2013-06-22\n",
        "0962"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2013-06-06\n",
        "0962"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " 2013-06-25\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "2.2 Viewing"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can view each image according to this pot number, date and angle view like this :\n",
      "\n",
      "Note : Angle top view is represented by negative number"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import alinea.phenomenal.viewer\n",
      "\n",
      "alinea.phenomenal.viewer.show_images([images['0962']['2013-06-06'][120], images['0962']['2013-06-22'][-1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:traits.has_traits:DEPRECATED: traits.has_traits.wrapped_class, 'the 'implements' class advisor has been deprecated. Use the 'provides' class decorator.\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "3. Plant Segmented Images"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.1 Binarization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from alinea.phenomenal.plant_1 import (plant_1_images,\n",
      "                                       plant_1_mask_mean_shift,\n",
      "                                       plant_1_mask_hsv,\n",
      "                                       plant_1_mask_clean_noise)\n",
      "\n",
      "from alinea.phenomenal.binarization_routine import meanshift_hsv, blur_hsv_erode_dilate\n",
      "from alinea.phenomenal.binarization_algorithm import get_mean_image\n",
      "\n",
      "images_0962_2013_06_06 = images['0962']['2013-06-06']\n",
      "if (-1) in images_0962_2013_06_06:\n",
      "    top_image = images_0962_2013_06_06.pop((-1))\n",
      "    mean_image = get_mean_image(images_0962_2013_06_06.values())\n",
      "    images_0962_2013_06_06[(-1)] = top_image\n",
      "else:\n",
      "    mean_image = get_mean_image(images_0962_2013_06_06.values())\n",
      "\n",
      "images_binarize_mean_shift = dict()\n",
      "for angle in images_0962_2013_06_06:\n",
      "    image = images_0962_2013_06_06[angle]\n",
      "    \n",
      "    if angle < 0:\n",
      "        hsv_min = (42, 75, 28)\n",
      "        hsv_max = (80, 250, 134)\n",
      "        images_binarize_mean_shift[angle]= blur_hsv_erode_dilate(image, hsv_min, hsv_max)\n",
      "    else:\n",
      "        hsv_min = (30, 11, 0)\n",
      "        hsv_max = (129, 254, 141)\n",
      "        mask_mean_shift = plant_1_mask_mean_shift()\n",
      "        mask_hsv = plant_1_mask_hsv()\n",
      "        mask_clean_noise = plant_1_mask_clean_noise()\n",
      "        \n",
      "        images_binarize_mean_shift[angle] = meanshift_hsv(\n",
      "            image,\n",
      "            mean_image,\n",
      "            hsv_min=hsv_min,\n",
      "            hsv_max=hsv_max,\n",
      "            mask_mean_shift=mask_mean_shift,\n",
      "            mask_hsv=mask_hsv,\n",
      "            mask_clean_noise=mask_clean_noise)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "3.1.1 Viewing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alinea.phenomenal.viewer.show_images([images['0962']['2013-06-06'][120], images_binarize_mean_shift[120]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.2 Remove plant support"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "3.2.2 Remove tutor"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from alinea.phenomenal.binarization_post_processing import morphology_close\n",
      "\n",
      "post_processing_images = dict()\n",
      "for angle in images_binarize_mean_shift:\n",
      "    if angle >= 0:\n",
      "        image = images_binarize_mean_shift[angle]\n",
      "        post_processing_images[angle] = morphology_close(image)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "3.2.3 Viewing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alinea.phenomenal.viewer.show_images([post_processing_images[120], images_binarize_mean_shift[120]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "3.3 Plant area estimation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "images_side = dict()\n",
      "for angle in post_processing_images:\n",
      "    if 0 <= angle <= 360:\n",
      "        images_side[angle] = post_processing_images[angle]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import alinea.phenomenal.model\n",
      "\n",
      "pixel_count = 0\n",
      "for angle in images_side:\n",
      "    pixel_count += cv2.countNonZero(images_side[angle])\n",
      "    \n",
      "\n",
      "pixel_count /= len(images_side)\n",
      "area = alinea.phenomenal.model.plant_area(pixel_count)\n",
      "print area"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.138621658544\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "4. Points cloud representation of 3D plant"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "4.1 Calibration & Projection"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "See [Calibration](Calibration.ipynb) notebook to calibrate camera if no camera parameters exist or load existing parameters like this :"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from alinea.phenomenal.plant_1 import plant_1_calibration_camera_side_2_target\n",
      "\n",
      "calibration = plant_1_calibration_camera_side_2_target()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "4.2 Multi-view reconstruction"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from alinea.phenomenal.plant_1 import plant_1_calibration_camera_side_2_target\n",
      "from alinea.phenomenal.multi_view_reconstruction import reconstruction_3d\n",
      "\n",
      "# Select images\n",
      "images_projections = list()\n",
      "for angle in range(0, 360, 30):\n",
      "    img = post_processing_images[angle]\n",
      "    projection = calibration.get_projection(angle)\n",
      "    images_projections.append((img, projection))\n",
      "\n",
      "voxel_size = 10\n",
      "# Multi-view reconstruction\n",
      "voxel_centers = reconstruction_3d(\n",
      "    images_projections, voxel_size=voxel_size, verbose=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iteration 1 / 9  :  8 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -  8\n",
        "Iteration 2 / 9  :  64 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -  8\n",
        "Iteration 3 / 9  :  64 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -  8\n",
        "Iteration 4 / 9  :  64 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -  17\n",
        "Iteration 5 / 9  :  136 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -  40\n",
        "Iteration 6 / 9  :  320 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -  89\n",
        "Iteration 7 / 9  :  712 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -  255\n",
        "Iteration 8 / 9  :  2040 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -  766\n",
        "Iteration 9 / 9  :  6128 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        " -  2702\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "4.3 Read & Write"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_path = '../../local/data_set_0962_A310_ARCH2013-05-13/reconstruction_3d/0962_2013-06-06'\n",
      "\n",
      "#Write\n",
      "alinea.phenomenal.misc.write_xyz(voxel_centers, file_path)\n",
      "\n",
      "#Read\n",
      "voxel_centers = alinea.phenomenal.misc.read_xyz(file_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "4.4 Viewing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alinea.phenomenal.viewer.show_points_3d(voxel_centers, scale_factor=2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "5. Mesh representation of 3D plant"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.1 Mesh"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import alinea.phenomenal.data_transformation\n",
      "import alinea.phenomenal.mesh\n",
      "\n",
      "matrix, index, origin = alinea.phenomenal.data_transformation.points_3d_to_matrix(voxel_centers, voxel_size)\n",
      "\n",
      "vertices, faces = alinea.phenomenal.mesh.meshing(matrix, origin, voxel_size)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.2 Normals"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "normals = alinea.phenomenal.mesh.compute_normal(vertices, faces)\n",
      "centers = alinea.phenomenal.mesh.center_of_vertices(vertices, faces)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.3 Surface area estimation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import skimage.measure\n",
      "\n",
      "surface = skimage.measure.mesh_surface_area(vertices, faces)\n",
      "\n",
      "print surface"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "396318.094072\n"
       ]
      }
     ],
     "prompt_number": 24
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.4 Read & write"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "file_path = '../local/data_set_0962_A310_ARCH2013-05-13/mesh/0962_2013-06-06'\n",
      "\n",
      "# Write\n",
      "alinea.phenomenal.misc.write_mesh(vertices, faces, file_path)\n",
      "\n",
      "# Read\n",
      "vertices, faces = alinea.phenomenal.misc.read_mesh(file_path)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "5.5 Viewing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alinea.phenomenal.viewer.show_mesh(vertices,\n",
      "                                   faces,\n",
      "                                   normals=normals,\n",
      "                                   centers=centers)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "6. PlantGL Format"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "6.1 Code"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import openalea.plantgl.scenegraph as sg\n",
      "\n",
      "scene = sg.Scene()\n",
      "tset = sg.FaceSet(pointList=vertices, indexList=faces)\n",
      "scene += tset"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "6.2 Viewing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import openalea.plantgl.all as pgl\n",
      "from PyQt4 import QtCore, QtGui\n",
      "qapp = QtGui.QApplication([])\n",
      "\n",
      "pgl.Viewer.display(scene)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}