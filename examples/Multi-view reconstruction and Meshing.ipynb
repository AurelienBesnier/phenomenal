{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-view reconstruction and Meshing\n",
    "\n",
    "## 0. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "\n",
    "import openalea.phenomenal.data as phm_data \n",
    "import openalea.phenomenal.display as phm_display\n",
    "import openalea.phenomenal.object as phm_obj\n",
    "import openalea.phenomenal.multi_view_reconstruction as phm_mvr\n",
    "import openalea.phenomenal.mesh as phm_mesh\n",
    "import openalea.phenomenal.display.notebook as phm_display_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Prerequisites\n",
    "\n",
    "### 1.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 13 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plant_number = 2 # Available : 1, 2, 3, 4 or 5\n",
    "bin_images = phm_data.bin_images(plant_number=plant_number)\n",
    "calibrations = phm_data.calibrations(plant_number=plant_number)\n",
    "\n",
    "phm_display.show_images(list(bin_images['side'].values()) + \n",
    "                        list(bin_images['top'].values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Multi-view reconstruction\n",
    "\n",
    "### 2.1 Associate images and projection function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def routine_select_ref_angle(bin_side_images):\n",
    "\n",
    "    max_len = 0\n",
    "    max_angle = None\n",
    "    \n",
    "    for angle in bin_side_images:\n",
    "    \n",
    "        x_pos, y_pos, x_len, y_len = cv2.boundingRect(cv2.findNonZero(bin_side_images[angle]))\n",
    "\n",
    "        if x_len > max_len:\n",
    "            max_len = x_len\n",
    "            max_angle = angle\n",
    "\n",
    "    return max_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs_angle_list = [routine_select_ref_angle(bin_images[\"side\"])]\n",
    "\n",
    "image_views = list()\n",
    "for id_camera in bin_images:\n",
    "    for angle in bin_images[id_camera]:\n",
    "        projection = calibrations[id_camera].get_projection(angle)\n",
    "    \n",
    "        image_ref = None\n",
    "        if id_camera == \"side\" and angle in refs_angle_list:\n",
    "            image_ref = bin_images[id_camera][angle]\n",
    "        \n",
    "        inclusive = False\n",
    "        if id_camera == \"top\":\n",
    "            inclusive = True\n",
    "            \n",
    "        image_views.append(phm_obj.ImageView(\n",
    "            bin_images[id_camera][angle], \n",
    "            projection, \n",
    "            inclusive=inclusive, \n",
    "            image_ref=image_ref))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Do multi-view reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artzet_s/code/phenomenal/src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py:544: NumbaWarning: \n",
      "Compilation is falling back to object mode WITH looplifting enabled because Function \"get_integrale_image\" failed type inference due to: Invalid use of Function(<function zeros_like at 0x7f2e4c0b3680>) with argument(s) of type(s): (array(uint8, 2d, C), dtype=Function(<class 'int'>))\n",
      " * parameterized\n",
      "In definition 0:\n",
      "    All templates rejected with literals.\n",
      "In definition 1:\n",
      "    All templates rejected without literals.\n",
      "This error is usually caused by passing an argument of a type that is unsupported by the named function.\n",
      "[1] During: resolving callee type: Function(<function zeros_like at 0x7f2e4c0b3680>)\n",
      "[2] During: typing of call at /home/artzet_s/code/phenomenal/src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py (546)\n",
      "\n",
      "\n",
      "File \"../src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py\", line 546:\n",
      "def get_integrale_image(img):\n",
      "    a = numpy.zeros_like(img, dtype=int)\n",
      "    ^\n",
      "\n",
      "  @numba.jit()\n",
      "/home/artzet_s/code/phenomenal/src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py:544: NumbaWarning: \n",
      "Compilation is falling back to object mode WITHOUT looplifting enabled because Function \"get_integrale_image\" failed type inference due to: cannot determine Numba type of <class 'numba.dispatcher.LiftedLoop'>\n",
      "\n",
      "File \"../src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py\", line 547:\n",
      "def get_integrale_image(img):\n",
      "    <source elided>\n",
      "    a = numpy.zeros_like(img, dtype=int)\n",
      "    for y, x in numpy.ndindex(a.shape):\n",
      "    ^\n",
      "\n",
      "  @numba.jit()\n",
      "/home/artzet_s/miniconda3/envs/phenomenal3/lib/python3.7/site-packages/numba/object_mode_passes.py:178: NumbaWarning: Function \"get_integrale_image\" was compiled in object mode without forceobj=True, but has lifted loops.\n",
      "\n",
      "File \"../src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py\", line 545:\n",
      "@numba.jit()\n",
      "def get_integrale_image(img):\n",
      "^\n",
      "\n",
      "  state.func_ir.loc))\n",
      "/home/artzet_s/miniconda3/envs/phenomenal3/lib/python3.7/site-packages/numba/object_mode_passes.py:187: NumbaDeprecationWarning: \n",
      "Fall-back from the nopython compilation path to the object mode compilation path has been detected, this is deprecated behaviour.\n",
      "\n",
      "For more information visit http://numba.pydata.org/numba-doc/latest/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit\n",
      "\n",
      "File \"../src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py\", line 545:\n",
      "@numba.jit()\n",
      "def get_integrale_image(img):\n",
      "^\n",
      "\n",
      "  warnings.warn(errors.NumbaDeprecationWarning(msg, state.func_ir.loc))\n",
      "/home/artzet_s/code/phenomenal/src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py:480: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  position = numpy.vstack(set(tuple(row) for row in position))\n",
      "/home/artzet_s/code/phenomenal/src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py:518: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  position = numpy.vstack(set(tuple(row) for row in position))\n",
      "/home/artzet_s/code/phenomenal/src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py:480: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  position = numpy.vstack(set(tuple(row) for row in position))\n",
      "/home/artzet_s/code/phenomenal/src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py:518: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  position = numpy.vstack(set(tuple(row) for row in position))\n",
      "/home/artzet_s/code/phenomenal/src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py:480: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  position = numpy.vstack(set(tuple(row) for row in position))\n",
      "/home/artzet_s/code/phenomenal/src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py:518: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  position = numpy.vstack(set(tuple(row) for row in position))\n",
      "/home/artzet_s/code/phenomenal/src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py:480: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  position = numpy.vstack(set(tuple(row) for row in position))\n",
      "/home/artzet_s/code/phenomenal/src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py:518: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  position = numpy.vstack(set(tuple(row) for row in position))\n",
      "/home/artzet_s/code/phenomenal/src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py:480: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  position = numpy.vstack(set(tuple(row) for row in position))\n",
      "/home/artzet_s/code/phenomenal/src/openalea/phenomenal/multi_view_reconstruction/multi_view_reconstruction.py:535: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  set(tuple(row) for row in voxels_position))\n"
     ]
    }
   ],
   "source": [
    "voxels_size = 16 # mm\n",
    "error_tolerance = 0\n",
    "voxel_grid = phm_mvr.reconstruction_3d(image_views, \n",
    "                                       voxels_size=voxels_size,\n",
    "                                       error_tolerance=error_tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Save / Load voxel grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_grid.write(\"plant_{}_size_{}.npz\".format(plant_number, voxels_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "voxel_grid = phm_obj.VoxelGrid.read(\"plant_{}_size_{}.npz\".format(plant_number, voxels_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c282cf444ba493eb028ca0780fbb22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 2.0, 1.2246467991473532e-16), quaterni…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phm_display_notebook.show_voxel_grid(voxel_grid, size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Meshing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Marching cubes : \n",
      "\tIso value :0.5\n",
      "\n",
      "\tThere are 10122 points.\n",
      "\tThere are 20116 polygons.\n",
      "================================================================================\n",
      "================================================================================\n",
      "Smoothing : \n",
      "\tFeature angle :120.0\n",
      "\tNumber of iteration :5\n",
      "\tPass band : 0.01\n",
      "\n",
      "================================================================================\n",
      "================================================================================\n",
      "Decimation : \n",
      "\tReduction (percentage) :0.9\n",
      "\n",
      "\tBefore decimation\n",
      "\t-----------------\n",
      "\tThere are 10122 points.\n",
      "\tThere are 20116 polygons.\n",
      "\n",
      "\tAfter decimation\n",
      "\t-----------------\n",
      "\tThere are 0.9 points.\n",
      "\tThere are 10122 polygons.\n",
      "================================================================================\n",
      "Number of vertices : 1019\n",
      "Number of faces : 2011\n"
     ]
    }
   ],
   "source": [
    "vertices, faces = phm_mesh.meshing(voxel_grid.to_image_3d(),\n",
    "                                   reduction=0.90,\n",
    "                                   smoothing_iteration=5,\n",
    "                                   verbose=True)\n",
    "\n",
    "print(\"Number of vertices : {nb_vertices}\".format(nb_vertices=len(vertices)))\n",
    "print(\"Number of faces : {nb_faces}\".format(nb_faces=len(faces)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3670cf9d6e94d66ae7fce000a444e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=46.0, position=(0.0, 2.0, 1.2246467991473532e-16), quaterni…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "phm_display_notebook.show_mesh(vertices, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
